{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ea024ef",
   "metadata": {},
   "source": [
    "# Assignment 1, Task B: Regression using tree methods.\n",
    "\n",
    "## The data:\n",
    "In this QSAR exercise, water solubility of various molecules is to be investigated. The dataset in use is the ESOL Dataset assembled by John Delaney, as provided here: https://huggingface.co/datasets/scikit-fingerprints/MoleculeNet_ESOL/tree/main.\n",
    "\n",
    "\n",
    "## The tasks:\n",
    "1) Inspect the data and clean if needed. Adhere to good practices!\n",
    "2) Calculate some molecular descriptors via the smiles strings using rdkit (partial snippet provided)\n",
    "3) Create a feature matrix X and a target vector y\n",
    "4) Three different models should be trained on the molecular descriptors and evaluated according to RMSE and their R2 score to compare their performance. For each model, additionally, the overfitting needs to be addressed.\n",
    "\n",
    "These three models have to be compared:\n",
    "- `DecisionTreeClassifier`\n",
    "- `RandomForestClassifier`\n",
    "- `GradientBoostingClassifier`\n",
    "\n",
    "For a first baseline performance, the models can be used as provided by `scikit`, but should include a random seed. \n",
    "\n",
    "5) Based on the model performance, take the best performing algorithm and optimise its hyperparameters using `GridSearchCV`\n",
    "\n",
    "6) Assess the feature importance\n",
    "\n",
    "7) Conclusion and discussion: Provide answers to the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f461fb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f98ef66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"esol.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8be1835",
   "metadata": {},
   "source": [
    "## 1. Inspect and clean the data\n",
    "Gain some overview of the data and assess NaNs and duplicates and clean if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be498947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55409f93",
   "metadata": {},
   "source": [
    "## 2. Create molecular descriptors from the Smiles\n",
    "Use the snippet below to calculate descriptors from the SMILES strings. Make sure to include the molecular weight, the logP and choose three more which you believe to impact the solubility, e.g. https://greglandrum.github.io/rdkit-blog/posts/2022-12-23-descriptor-tutorial.html or here: https://deepwiki.com/rdkit/rdkit/6.1-molecular-descriptors-and-properties "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9bc64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_descriptors(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    return pd.Series({\n",
    "        \"MolWt\": Descriptors.MolWt(mol),\n",
    "        \"LogP\": Descriptors.MolLogP(mol)\n",
    "    })\n",
    "\n",
    "# Apply to dataframe\n",
    "descriptor_df = df[\"SMILES\"].apply(compute_descriptors)\n",
    "\n",
    "# Combine descriptors with original data\n",
    "df_full = pd.concat([df, descriptor_df], axis=1)\n",
    "\n",
    "# Remove rows where descriptor calculation failed\n",
    "df_full = df_full.dropna()\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbf2a47",
   "metadata": {},
   "source": [
    "## 3. Create the feature matrix and target vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e10073",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8430d770",
   "metadata": {},
   "source": [
    "## 4. Train the models\n",
    "Use a classic train-test split of 0.2 including a random seed. For training and predicting labels, take note of the time the process takes for each model (does not necessarily have to be coded, can also be estimated). Make sure to predict labels for both training and test splits in order to identify overfitting. Use the RMSE and R2 as metrics for evaluation of the baseline performance of the models. Make sure to consider overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d4e32b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8c4c48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d3d5353",
   "metadata": {},
   "source": [
    "Use the best model and plot the predictions over the true values (y_test vs. y_pred) in a scatterplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74646a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9698c85e",
   "metadata": {},
   "source": [
    "## 5. Hyperparameter tuning of the best model\n",
    "Use GridSearchCV to optimise the hyperparameters for the best model. Use a reasonable parameter grid (2-3 different values max. for each parameter you want to optimise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dd5ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": [],\n",
    "    \"learning_rate\": [],\n",
    "    \"max_depth\": [],\n",
    "    \"min_samples_split\": [],\n",
    "    \"min_samples_leaf\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2699fd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7964edd0",
   "metadata": {},
   "source": [
    "Extract the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f826262",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(\"Best Parameters:\")\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4e1562",
   "metadata": {},
   "source": [
    "Useful tool: Export (and reimport) your best model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdba1f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "# export the best model:\n",
    "joblib.dump(best_model, \"best_model.joblib\")\n",
    "# reload the best model:\n",
    "loaded_model = joblib.load(\"best_model.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8d3918",
   "metadata": {},
   "source": [
    "Evaluate the best model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fcf213",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8872e46",
   "metadata": {},
   "source": [
    "Plot the predicted vs. the true solubility again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134e81fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1399d39c",
   "metadata": {},
   "source": [
    "## 6. Feature importance\n",
    "Investigate the feature importance for your best model using the snippet below (but with your descriptors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b650ed5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "    \"MolWt\", \"LogP\"\n",
    "]\n",
    "\n",
    "importances = best_model.feature_importances_\n",
    "\n",
    "for name, imp in sorted(zip(feature_names, importances), key=lambda x: -x[1]):\n",
    "    print(f\"{name}: {imp:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df46b295",
   "metadata": {},
   "source": [
    "## 7. Conclusion and discussion\n",
    "- Which model performed the best?\n",
    "- Which model showed the worst overfitting?\n",
    "- Did the GridSearchCV improve the model? Is the difference to be considered significant?\n",
    "- Which descriptors (besides the logP) had the most influence on the solubility?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86540d8d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSA104",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
